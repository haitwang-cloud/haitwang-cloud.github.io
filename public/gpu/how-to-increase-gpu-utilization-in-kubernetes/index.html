<!doctype html>




<script src="/livereload.js?mindelay=10&amp;v=2&amp;port=53654&amp;path=livereload" data-no-instant defer></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1313460867822205"
     crossorigin="anonymous"></script>





































<html
  class="not-ready lg:text-base"
  style="--bg: #f8f5d7"
  lang="zh-CN"
>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>Kubernetes GPU 优化：最大化 GPU 利用率 - Tim Wang的技术博客</title>

  
  <meta name="theme-color" />

  
  
  
  
  <meta name="description" content="本文是How to Increase GPU Utilization in Kubernetes with NVIDIA MPS的中文翻译版本，内容有删减
本文主要介绍在 Kubernetes 中集成 NVIDIA 多进程服务（MPS,Multi-Process Service），以在工作负载之间共享 GPU，以最大化利用率并降低基础设施成本。
大多数workload不需要每个 GPU 的全部内存和计算资源。因此，将一个 GPU 在多个进程之间共享对于提高 GPU 利用率和降低基础设施成本至关重要。
在 Kubernetes 中，可以通过将单个 GPU 公开为多个资源（即切片），每个切片具有特定的内存和计算大小，这些资源可以由单个容器请求来实现。通过为每个容器只创建所需的 GPU 切片，您可以释放集群中富余的GPU资源。这些资源可用于调度更多的 Pod，或允许您减少集群中的GPU节点数。无论哪种方式，在进程之间共享 GPU 都可以帮助您降低基础设施成本。
Kubernetes 中的 GPU 支持由 NVIDIA Kubernetes Device Plugin 提供，该插件目前仅支持两种 GPU 共享策略：时间切片和多实例 GPU（MIG,Multi-Instance GPU）。但是，还有一种 GPU 共享策略，它平衡了时间切片和 MIG 的优缺点：多进程服务 Multi-Process Service (MPS)。尽管 MPS 不受 NVIDIA Device Plugin 支持，但在 Kubernetes 中使用它仍然可行。
在本文中，我们将首先对比所有三种 GPU 共享技术的优缺点，然后提供有关如何在 Kubernetes 中使用 MPS 的逐步指南。此外，我们还提出了一种自动化 MPS 资源管理的解决方案，以优化利用率并降低运营成本：动态MPS (Dynamic MPS Partitioning)。" />
  <meta name="author" content="Tim Wang" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="http://localhost:53654/main.min.css" />

  
  
  
  
  
  <link rel="preload" as="image" href="http://localhost:53654/theme.png" />

  
  
  
  
  <link rel="preload" as="image" href="https://gravatar.com/haitaoking1993" />
  
  

  
  
  <link rel="preload" as="image" href="http://localhost:53654/github.svg" />
  
  <link rel="preload" as="image" href="http://localhost:53654/linkedin.svg" />
  
  <link rel="preload" as="image" href="http://localhost:53654/rss.svg" />
  
  

  
  
  <script
    defer
    src="http://localhost:53654/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
  
  

  
  <link rel="icon" href="http://localhost:53654/favicon.ico" />
  <link rel="apple-touch-icon" href="http://localhost:53654/apple-touch-icon.png" />

  
  <meta name="generator" content="Hugo 0.127.0">

  
  
  
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    <header class="mx-auto flex h-[4.5rem] max-w-3xl px-8 lg:justify-center">
  <div class="relative z-50 mr-auto flex items-center">
    <a
      class="-translate-x-[1px] -translate-y-[1px] text-2xl font-semibold"
      href="http://localhost:53654/"
      >Tim Wang的技术博客</a
    >
    <div
      class="btn-dark text-[0] ml-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"
      role="button"
      aria-label="Dark"
    ></div>
  </div>

  <div
    class="btn-menu relative z-50 -mr-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
    role="button"
    aria-label="Menu"
  ></div>

  

  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = '#f8f5d7'.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
  >
    
    

    
    <nav
      class="mt-12 flex justify-center space-x-10 dark:invert lg:ml-12 lg:mt-0 lg:items-center lg:space-x-6"
    >
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./github.svg)"
        href="https://github.com/haitwang-cloud"
        target="_blank"
        rel="me"
      >
        github
      </a>
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./linkedin.svg)"
        href="https://linkedin.com/in/tim-wang-505213166"
        target="_blank"
        rel="me"
      >
        linkedin
      </a>
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./rss.svg)"
        href="http://localhost:53654/index.xml"
        target="_blank"
        rel="alternate"
      >
        rss
      </a>
      
    </nav>
    
  </div>
</header>


    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100%-9rem)] max-w-3xl px-8 pb-16 pt-12 dark:prose-invert"
    >
      

<article>
  <header class="mb-16">
    <h1 class="!my-0 pb-2.5">Kubernetes GPU 优化：最大化 GPU 利用率</h1>

    
    <div class="text-sm antialiased opacity-60">
      
      <time>Jun 20, 2024</time>
      
      
      
      
    </div>
    
  </header>

  <section><blockquote>
<p>本文是<a href="https://towardsdatascience.com/how-to-increase-gpu-utilization-in-kubernetes-with-nvidia-mps-e680d20c3181">How to Increase GPU Utilization in Kubernetes with NVIDIA MPS</a>的中文翻译版本，内容有删减</p>
</blockquote>
<blockquote>
<p>本文主要介绍在 Kubernetes 中集成 NVIDIA 多进程服务（MPS,Multi-Process Service），以在工作负载之间共享 GPU，以最大化利用率并降低基础设施成本。</p>
</blockquote>
<p>大多数workload不需要每个 GPU 的全部内存和计算资源。因此，将一个 GPU 在多个进程之间共享对于提高 GPU 利用率和降低基础设施成本至关重要。</p>
<p>在 Kubernetes 中，可以通过将单个 GPU 公开为多个资源（即切片），每个切片具有特定的内存和计算大小，这些资源可以由单个容器请求来实现。通过为每个容器只创建所需的 GPU 切片，您可以释放集群中富余的GPU资源。这些资源可用于调度更多的 Pod，或允许您减少集群中的GPU节点数。无论哪种方式，在进程之间共享 GPU 都可以帮助您降低基础设施成本。</p>
<p>Kubernetes 中的 GPU 支持由 <a href="https://github.com/NVIDIA/k8s-device-plugin">NVIDIA Kubernetes Device Plugin</a> 提供，该插件目前仅支持两种 GPU 共享策略：时间切片和多实例 GPU（MIG,Multi-Instance GPU）。但是，还有一种 GPU 共享策略，它平衡了时间切片和 MIG 的优缺点：多进程服务 <a href="https://docs.nvidia.com/deploy/mps/index.html"><strong>Multi-Process Service (MPS)</strong></a>。尽管 MPS 不受 NVIDIA Device Plugin 支持，但在 Kubernetes 中使用它仍然可行。</p>
<p>在本文中，我们将首先对比所有三种 GPU 共享技术的优缺点，然后提供有关如何在 Kubernetes 中使用 MPS 的逐步指南。此外，我们还提出了一种自动化 MPS 资源管理的解决方案，以优化利用率并降低运营成本：动态MPS  (<strong>Dynamic MPS Partitioning</strong>)。</p>
<p>目前使用GPU的方式有三种：</p>
<ol>
<li><strong>Time slicing</strong>：将 GPU 的使用时间分为多个时间段，并按顺序分配给容器。这是一种简单有效的方法来共享 GPU，但它可能会导致容器的性能不一致。</li>
<li><strong>Multi-instance GPU (MIG)</strong>：将单个 GPU 分为多个逻辑 GPU，每个逻辑 GPU 可以由一个容器使用。这可以提高 GPU 的利用率，因为每个容器只使用它所需的 GPU 资源。但是，MIG 需要额外的软件和硬件支持，这可能会增加成本。</li>
<li><strong>Multi-Process Service (MPS)</strong>：将多个 GPU 组合在一起，并由一个进程管理，该进程可以将 GPU 资源分配给多个容器。MPS 可以提供比时间切片和 MIG 更高级的 GPU 共享控制，但它也更复杂。</li>
</ol>
<h4 id="time-slicing"><strong>Time slicing</strong></h4>
<p>时间切片是一种机制，它允许在繁忙的 GPU 上交错地运行用户的workload。时间切片主要是调用GPU 时间切片调度程序，该调度程序通过<strong>时间共享</strong>并发执行多个 CUDA 进程。</p>
<p>当启用时间切片时，GPU 会通过在一定时间间隔内在进程之间切换，以公平共享的方式在不同进程之间共享其计算资源。这会产生与连续上下文切换相关的计算时间开销，这会转化为抖动和更高的延迟。</p>
<blockquote>
<p>时间切片几乎被所有 GPU 架构支持，是 Kubernetes 集群中共享 GPU 的最简单解决方案。但是，进程之间不断切换会产生计算时间开销。此外，时间切片在共享 GPU 的进程之间不提供任何内存隔离级别，也不提供任何内存分配限制，这可能导致频繁的 OOM（内存不足）错误。</p>
</blockquote>
<p>如果您想在 Kubernetes 中使用时间切片，您只需要编辑 NVIDIA Device Plugin 配置。例如，您可以将以下配置应用于具有 2 个 GPU 的节点。该节点上运行的设备插件将向 Kubernetes 申请 8 个 <code>nvidia.com/gpu</code> 资源，而不是 2 个。这允许每个 GPU 被最多 4 个容器共享。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">version</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">sharing</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">timeSlicing</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nvidia.com/gpu</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">4</span>
</span></span></code></pre></div><p>如果你想知道关于时间切片在 Kubernetes 中的更多信息，请参考 <a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/gpu-sharing.html">NVIDIA GPU Operator documentation</a>。</p>
<h4 id="multi-instance-gpu-mig">Multi-Instance GPU (MIG)</h4>
<p>多实例 GPU（Multi-Instance GPU，简称 MIG）是一种在 NVIDIA <a href="https://www.nvidia.com/en-us/data-center/ampere-architecture/">Ampere</a> 和 <a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/">Hopper</a> 架构上可用的技术，允许将 GPU 安全地划分为最多七个独立的 GPU 实例，每个实例都具有自己的高带宽内存、缓存和计算核心。</p>
<p>这些独立的 GPU 切片被称为 MIG 设备，并且它们采用一种格式命名，该格式指示了设备的计算和内存资源。例如，2g.20gb 对应于具有 20 GB 内存的 GPU 切片。</p>
<p>MIG 不允许创建自定义大小和数量的 GPU 切片，因为每个 GPU 型号仅支持一组<a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#supported-profiles">特定的 MIG 配置</a>。这降低了您对 GPU 进行分区的粒度。此外，MIG 设备必须根据特定的<a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/#partitioning">规则</a>进行创建，这进一步限制了使用的灵活性。</p>
<blockquote>
<p>MIG 是在进程之间提供最高级别隔离的 GPU 共享方法。然而，它缺乏灵活性，并且仅与少数 GPU 架构（Ampere 和 Hopper）兼容。</p>
</blockquote>
<p>您可以使用 <a href="https://developer.nvidia.com/nvidia-system-management-interface">nvidia-smi</a> 命令行界面手动创建和删除 MIG 设备，也可以使用 <a href="https://developer.nvidia.com/nvidia-management-library-nvml">NVML</a> 进行编程方式操作。然后，NVIDIA 设备插件通过 <a href="https://docs.google.com/document/d/1mdgMQ8g7WmaI_XVVRrCvHPFPOMCm5LQD5JefgAh6N8g/edit#bookmark=id.vj44q8ogvavv">不同的命名策略</a> 将这些设备作为 Kubernetes 资源公开。例如，使用 <code>mixed</code> 策略，设备 <code>1g.10gb</code> 会被公开为 <code>nvidia.com/mig-1g.10gb</code>。而策略 <code>single</code> 则将设备公开为通用的 <code>nvidia.com/gpu</code> 资源。</p>
<p>通过 nvidia-smi CLI 或 NVML 手动管理 MIG 设备相对不太实用：在 Kubernetes 中，NVIDIA GPU Operator 提供了一种更简便的方式来使用 MIG，尽管仍然有一些限制。该Operator使用 <a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/gpu-operator-mig.html#configuring-mig-profiles">ConfigMap</a> 定义了一组允许的 MIG 配置，您可以通过添加label来将其应用于该节点。</p>
<p>您可以编辑此 ConfigMap 来定义您自己的自定义 MIG 配置，就像下面的示例所示。在此示例中，一个节点被标记为 <code>nvidia.com/mig.config=all-1g.5gb</code>。因此，GPU Operator 将将该节点的每个 GPU 划分为七个 1g.5gb MIG 设备，然后将其作为 <code>nvidia.com/mig-1g.5gb</code> 资源暴露给 Kubernetes 使用。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ConfigMap</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">default-mig-parted-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">data</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">config.yaml</span>: |<span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    version: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    mig-configs:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      all-1g.5gb:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        - devices: all
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          mig-enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          mig-devices:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            &#34;1g.5gb&#34;: 7
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      all-2g.10gb:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        - devices: all
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          mig-enabled: true
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          mig-devices:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            &#34;2g.10gb&#34;: 3</span>    
</span></span></code></pre></div><p>为了有效地利用带有 NVIDIA GPU Operator 的集群资源，集群管理员将需要不断修改 ConfigMap，以使 MIG 大小适应不断变化的工作负载计算需求。</p>
<p>这是非常不实际的。尽管这种方法当然比 SSH 连接到节点并手动创建/删除 MIG 设备要好，但对于集群管理员来说，这是非常繁重和耗时的工作。因此，通常情况下，MIG 设备的配置很少会随着时间的推移发生变化，或者根本不会应用，而在这两种情况下，都会导致 GPU 利用率的显著低效，从而增加基础设施成本。</p>
<p>可以通过<a href="https://docs.nebuly.com/nos/dynamic-gpu-partitioning/overview/">Dynamic GPU Partitioning</a>来克服这一挑战。在本文的后面部分，我们将了解如何使用开源模块 <code>nos</code> 动态划分 GPU，并使用 MPS，该方法也适用于 MIG。</p>
<h4 id="multi-process-service-mps">Multi-Process Service (MPS)</h4>
<p>多进程服务（Multi-Process Service，简称 MPS）是CUDA应用编程接口（API）的客户端-服务器实现，用于在同一GPU上并发运行多个进程。</p>
<p>服务器管理GPU访问，为客户端提供并发性。客户端通过客户端运行时连接到服务器，该运行时内置于CUDA驱动库中，并且可以由任何CUDA应用程序透明地调用。</p>
<blockquote>
<p>MPS 几乎与所有现代 GPU 兼容，并提供了最高的灵活性，允许创建具有可分配内存量和可用计算能力的任意限制的 GPU 切片。然而，它不强制在进程之间实现完全的内存隔离。在大多数情况下，MPS 在 MIG 和时间分片之间表示了一个很好的折衷方案。</p>
</blockquote>
<p>与时间分片相比，MPS 通过通过“空间共享”在并行中运行进程，从而消除了上下文切换的开销，从而实现更好地计算性能。此外，MPS 为每个进程提供了自己的 GPU 内存地址空间。这允许对进程的内存限制，克服了时间分片共享的限制。</p>
<p>然而，在 MPS 中，客户端进程之间并不完全隔离。实际上，尽管 MPS 允许限制客户端的计算和内存资源，但它不提供错误隔离和内存保护。这意味着一个客户端进程如果崩溃并导致整个 GPU 重置，影响在 GPU 上运行的所有其他进程。</p>
<p>NVIDIA Kubernetes 设备插件不支持 MPS 分区，这使得在 Kubernetes不能直接使用它。在接下来的章节中，我们将探讨通过利用 <code>nos</code> 和不同的 Kubernetes 设备插件来充分利用 MPS 进行 GPU 共享的替代方法。</p>
<p>您可以通过使用 Helm 安装<a href="https://github.com/nebuly-ai/k8s-device-plugin">这个分支</a>的 NVIDIA 设备插件，来在 Kubernetes 集群中启用 MPS 分区：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>helm install oci://ghcr.io/nebuly-ai/helm-charts/nvidia-device-plugin <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --version 0.13.0 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --generate-name <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -n nebuly-nvidia <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --create-namespace
</span></span></code></pre></div><p>默认情况下，Helm chart会在所有标记为 <code>nos.nebuly.com/gpu-partitioning=mps</code> 的节点上部署启用 MPS 模式的设备插件。要启用特定节点 GPU 上的 MPS 分区，只需添加label <code>nos.nebuly.com/gpu-partitioning=mps</code> 。</p>
<p>很可能您的集群中已经安装了 NVIDIA 设备插件的一个版本。如果您不想将其移除，您可以选择在原始的 NVIDIA 设备插件旁边安装这个分支的插件，并仅在特定节点上运行它。为了实现这一点，重要的是确保这两个插件中只有一个在节点上运行。如<a href="https://github.com/nebuly-ai/k8s-device-plugin#installation">安装指南</a>中所述，可以通过编辑<strong>原始</strong> NVIDIA 设备插件的规范，向其 <code>spec.template.spec</code> 添加<code>affinity</code>，以确保它不会运行在与分支插件目标相同的节点上：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">affinity</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">nodeAffinity</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">nodeSelectorTerms</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">matchExpressions</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">key</span>: <span style="color:#ae81ff">nos.nebuly.com/gpu-partitioning</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">operator</span>: <span style="color:#ae81ff">NotIn</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">values</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">mps</span>
</span></span></code></pre></div><p>在安装设备插件后，您可以通过编辑其配置的 <code>sharing.mps</code> 部分，将 GPU 暴露为多个 MPS 资源。例如，下面的配置告诉插件将索引为 <code>0</code> 的 GPU 暴露给 Kubernetes，作为<code>2</code>个 GPU 资源（命名为 <code>nvidia.com/gpu-4gb</code>），每个资源具有 4GB 的内存：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">version</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">sharing</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">mps</span>: 
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">nvidia.com/gpu</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">rename</span>: <span style="color:#ae81ff">nvidia.com/gpu-4gb</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memoryGB</span>: <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">devices</span>: [<span style="color:#e6db74">&#34;0&#34;</span>]
</span></span></code></pre></div><p>此时Kubernetes 上公开的资源名称、分区大小和副本数量可以根据需要进行配置。回到上面的例子，一个容器可以如下请求 4GB GPU 内存的一部分</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mps-partitioning-example</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">hostIPC</span>: <span style="color:#66d9ef">true</span> <span style="color:#75715e"># </span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">securityContext</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">runAsUser</span>: <span style="color:#ae81ff">1000</span> <span style="color:#75715e"># </span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">sleepy</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#34;busybox:latest&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">command</span>: [<span style="color:#e6db74">&#34;sleep&#34;</span>, <span style="color:#e6db74">&#34;120&#34;</span>]
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">nvidia.com/gpu-4gb</span>: <span style="color:#e6db74">&#34;1&#34;</span> <span style="color:#75715e">#</span>
</span></span></code></pre></div><p>请注意，对于请求 MPS 资源的容器，会存在一些限制条件：</p>
<ol>
<li>容器必须使用与部署在设备插件上的 MPS 服务器相同的用户ID运行，默认为 1000。您可以通过编辑设备插件chart的 <code>mps.userID</code> 值来更改它。</li>
<li>Pod 规范必须包括 <code>hostIPC: true</code>。由于 MPS 要求客户端和服务器共享相同的内存空间，我们需要允许 Pod 访问主机节点的 IPC 命名空间，以便它可以与运行在上面的 MPS 服务器进行通信。</li>
</ol>
<p>在上面的例子中，容器只能在共享的 GPU 上分配最多 2GB 的内存。如果尝试分配更多内存，它将会因为内存不足（OOM）错误而崩溃，而不会影响其他 Pod。</p>
<p>然而，需要指出的是，<code>nvidia-smi</code> 绕过 MPS 客户端运行时访问 NVIDIA 驱动程序。因此，在容器内运行 <code>nvidia-smi</code> 将在其输出中显示整个 GPU 资源：</p>
<p>总体而言，通过设备插件配置来管理 MPS 资源是复杂且耗时的。相反，最好只创建请求 MPS 资源的 Pod，并让某个自动化系统来进行分配和管理它们</p>
<p><img src="./pics/nvidia-smi.webp" alt=""></p>
<h4 id="dynamic-mps-partitioning">Dynamic MPS Partitioning</h4>
<p>To apply dynamic partitioning, we need to use <code>[nos](https://github.com/nebuly-ai/nos)</code>, an open-source module to efficiently run GPU workloads on Kubernetes.
为了应用动态分区，我们需要使用 <code>[nos](https://github.com/nebuly-ai/nos)</code>，这是一个开源模块，用于在 Kubernetes 上高效地运行 GPU 工作负载。</p>
<p>我已经介绍了如何使用 <code>nos</code> 进行基于多实例 GPU（MIG）的动态 GPU 划分。因此，在这里我们不会深入探讨细节，因为 <code>nos</code> 以相同的方式管理 MPS 划分。有关更多信息，您可以参考文章<a href="https://medium.com/towards-data-science/dynamic-mig-partitioning-in-kubernetes-89db6cdde7a3">在 Kubernetes 中进行动态 MIG 划分</a>，或查看 <code>nos</code> 的<a href="https://docs.nebuly.com/nos/overview/">文档</a>。</p>
<p>MPS 和 MIG 的动态划分之间唯一的区别在于用于告知 <code>nos</code> 应在哪些节点上管理 GPU 划分的标签值。对于 MPS，您需要对节点进行以下标记：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>kubectl label nodes &lt;node-names&gt; <span style="color:#e6db74">&#34;nos.nebuly.com/gpu-partitioning=mps&#34;</span>
</span></span></code></pre></div><h2 id="总结">总结</h2>
<p>GPU 切片是提高 GPU 利用率和降低基础设施成本的关键。</p>
<p>有三种方法可以实现：时间切片、多实例 GPU（MIG）和多进程服务（MPS）。时间切片是共享 GPU 的最简单技术，但它缺乏内存隔离，并会引入性能损失的开销。另一方面，MIG 提供最高级别的隔离，但其支持的配置和“切片”大小有限，因此缺乏灵活性。</p>
<blockquote>
<p>MPS 是 MIG 和时间分片之间的一个有效折衷方案。与 MIG 不同，它允许创建任意大小的 GPU 切片。与时间分片不同，它允许强制内存分配限制，并减少多个容器竞争共享 GPU 资源时可能出现的内存不足（OOM）错误。</p>
</blockquote>
<p>目前，NVIDIA 设备插件不支持 MPS。然而，只需安装另一个支持 MPS 的设备插件即可启用 MPS。</p>
<p>然而，MPS 静态配置无法自动调整以适应不断变化的工作负载需求，因此无法为每个 Pod 提供所需的 GPU 资源，尤其是在工作负载要求在内存和计算方面变化多样的情况下。</p>
<blockquote>
<p>nos 通过动态 GPU 划分克服了 MPS 静态配置的限制，从而增加了 GPU 利用率，并减轻了手动定义和应用在集群节点上运行的设备插件实例的 MPS 配置的操作负担。</p>
</blockquote>
<p>总之，我们必须指出，在某些情况下，MPS 的灵活性是不必要的，而由 MIG 提供的完全隔离是至关重要的。然而，在这些情况下，仍然可以通过 nos 充分利用动态 GPU 划分，因为它支持两种划分模式。</p>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><a href="https://docs.nebuly.ai/nos/dynamic-gpu-partitioning/">Dynamic GPU Partitioning documentation</a></li>
<li><a href="https://github.com/nebuly-ai/nos">Nos source code</a></li>
<li><a href="https://github.com/NVIDIA/k8s-device-plugin">NVIDIA Kubernetes Device Plugin</a></li>
<li><a href="https://github.com/nebuly-ai/k8s-device-plugin">NVIDIA Kubernetes Device Plugin (Forked)</a></li>
<li><a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/getting-started.html">NVIDIA GPU Operator documentation</a></li>
</ul>
<p>Special thanks to <a href="https://medium.com/u/2c53981c8a83">Emile Courthoud</a> for their review and contributions to this article.</p>
</section>

  
  

  
  
  
  
  

  
  

  
  

  


  
  <div class="giscus mt-24"></div>
  <script
    src="https://giscus.app/client.js"
    data-repo="haitwang-cloud/haitwang-cloud.github.io"
    data-repo-id="R_kgDOMH03cQ"
    data-category="General"
    data-category-id="DIC_kwDOMH03cc4CgVak"
    data-mapping="pathname"
    data-strict="1"
    data-reactions-enabled="0"
    data-emit-metadata="0"
    data-input-position="top"
    data-theme="light"
    data-lang="zh-CN"
    data-loading="lazy"
    crossorigin="anonymous"
    async
  ></script>
  
</article>


    </main>

    <footer
  class="opaco mx-auto flex h-[4.5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"
>
  <div class="mr-auto">
    &copy; 2024
    <a class="link" href="http://localhost:53654/">Tim Wang的技术博客</a>
  </div>
  <a class="link mx-6" href="https://gohugo.io/" rel="noopener" target="_blank"
    >Powered by Hugo️️</a
  >️
  <a
    class="link"
    href="https://github.com/nanxiaobei/hugo-paper"
    rel="noopener"
    target="_blank"
    >✎ Paper</a
  >
</footer>

  </body>
</html>
