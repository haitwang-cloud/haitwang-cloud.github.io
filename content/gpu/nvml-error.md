+++
title = 'å¦‚ä½•è§£å†³ `Failed to initialize NVML: Unknown Error` é—®é¢˜'
date = 2024-06-14T17:42:52+08:00
draft = false
+++

> æœ¬æ–‡æ˜¯[NOTICE: Containers losing access to GPUs with error: "Failed to initialize NVML: Unknown Error"](https://github.com/NVIDIA/nvidia-container-toolkit/issues/48)çš„ä¸­æ–‡ç¿»è¯‘ç‰ˆæœ¬ï¼Œå†…å®¹æœ‰åˆ å‡ï¼Œäº²æµ‹è¯¥æ–¹æ³•æœ‰æ•ˆã€‚
> 
# å¦‚ä½•è§£å†³ `Failed to initialize NVML: Unknown Error` é—®é¢˜

## æ¦‚è¿°

åœ¨æŸäº›ç‰¹å®šçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å‘ç°k8så®¹å™¨å¯èƒ½ä¼šçªç„¶ä»æœ€åˆè¿æ¥åˆ°çš„GPUä¸Šåˆ†ç¦»ã€‚æˆ‘ä»¬å·²ç»ç¡®å®šäº†è¿™ä¸ªé—®é¢˜çš„æ ¹æœ¬åŸå› ï¼Œå¹¶ç¡®å®šäº†å¯èƒ½å‘ç”Ÿè¿™ç§æƒ…å†µçš„å—å½±å“ç¯å¢ƒã€‚åœ¨æœ¬æ–‡æ¡£çš„æœ«å°¾æä¾›äº†å—å½±å“ç¯å¢ƒçš„è§£å†³æ–¹æ³•ï¼Œç›´åˆ°å‘å¸ƒé€‚å½“çš„ä¿®å¤ä¸ºæ­¢ã€‚

## é—®é¢˜æ€»ç»“


æˆ‘ä»¬å‘ç°å½“ä½¿ç”¨containeræ¥ç®¡ç†GPUå·¥ä½œè´Ÿè½½æ—¶ï¼Œç”¨æˆ·containerå¯èƒ½ä¼šçªç„¶å¤±å»å¯¹GPUçš„è®¿é—®æƒé™ã€‚è¿™ç§æƒ…å†µå‘ç”Ÿåœ¨ä½¿ç”¨systemdæ¥ç®¡ç†å®¹å™¨çš„cgroupsæ—¶ï¼Œå½“è§¦å‘é‡æ–°åŠ è½½ä»»ä½•åŒ…å«å¯¹NVIDIA GPUçš„å¼•ç”¨çš„Unitæ–‡ä»¶æ—¶ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡æ‰§è¡Œ`systemctl daemon-reload`ï¼‰ã€‚

å½“ä½ çš„containerå¤±å»å¯¹GPUçš„è®¿é—®æƒé™æ—¶ï¼Œä½ å¯èƒ½ä¼šçœ‹åˆ°ç±»ä¼¼äºä»¥ä¸‹é”™è¯¯æ¶ˆæ¯ï¼š

```shell
Failed to initialize NVML: Unknown Error
```
ä¸€æ—¦å‘ç”Ÿä¸Šè¿° â¬†ï¸ï¼Œå°±éœ€è¦æ‰‹åŠ¨åˆ é™¤å—å½±å“çš„containerï¼Œç„¶åé‡æ–°å¯åŠ¨å®ƒä»¬ã€‚

å½“containeré‡æ–°å¯åŠ¨ï¼ˆæ‰‹åŠ¨æˆ–è‡ªåŠ¨ï¼Œå–å†³äºæ˜¯å¦ä½¿ç”¨å®¹å™¨ç¼–æ’å¹³å°ï¼‰ï¼Œå®ƒå°†é‡æ–°è·å¾—å¯¹GPUçš„è®¿é—®æƒé™ã€‚

æ­¤é—®é¢˜çš„æ ¹æºåœ¨äºï¼Œæœ€è¿‘ç‰ˆæœ¬çš„`runc`è¦æ±‚åœ¨`/dev/char`ä¸‹é¢ä¸ºæ³¨å…¥åˆ°å®¹å™¨ä¸­çš„ä»»ä½•è®¾å¤‡èŠ‚ç‚¹æä¾›ç¬¦å·é“¾æ¥ã€‚ä¸å¹¸çš„æ˜¯ï¼ŒNVIDIAè®¾å¤‡å¹¶æ²¡æœ‰è¿™äº›ç¬¦å·é“¾æ¥ï¼ŒNVIDIA GPUé©±åŠ¨ä¹Ÿæ²¡æœ‰ï¼ˆå½“å‰ï¼‰æä¾›è‡ªåŠ¨åˆ›å»ºè¿™äº›é“¾æ¥çš„æ–¹æ³•

## å—å½±å“çš„ç¯å¢ƒ


**å¦‚æœä½ ä½¿ç”¨`runc`å¹¶åœ¨é«˜çº§å®¹å™¨è¿è¡Œæ—¶ï¼ˆCRIï¼‰å¯ç”¨`systemd cgroup`ç®¡ç†çš„ç¯å¢ƒï¼Œé‚£ä¹ˆä½ å¯èƒ½ä¼šå—åˆ°è¿™ä¸ªé—®é¢˜çš„å½±å“**

å¦‚æœä½ æ²¡æœ‰ä½¿ç”¨`systemd`æ¥ç®¡ç†`cgroup`ï¼Œé‚£ä¹ˆå®ƒå°±ä¸ä¼šå—åˆ°è¿™ä¸ªé—®é¢˜çš„å½±å“ã€‚
ä¸‹é¢æ˜¯å¯èƒ½ä¼šå—å½±å“çš„çš„ç¯å¢ƒçš„è¯¦å°½åˆ—è¡¨:
### ä½¿ç”¨`containerd`/`runc`çš„Dockerç¯å¢ƒ
#### ç‰¹å®šæ¡ä»¶
- å¯ç”¨äº†`systemd`çš„`cgroup`é©±åŠ¨ç¨‹åºï¼ˆä¾‹å¦‚ï¼Œåœ¨`/etc/docker/daemon.json`ä¸­è®¾ç½®äº†å‚æ•°`"exec-opts": ["native.cgroupdriver=systemd"]`ï¼‰
- ä½¿ç”¨äº†æ›´æ–°çš„`Docker`ç‰ˆæœ¬ï¼Œå…¶ä¸­`systemd cgroup`ç®¡ç†è¢«é»˜è®¤è®¾ç½®çš„ï¼ˆå³ï¼Œåœ¨Ubuntu 22.04ä¸Šï¼‰ã€‚

>`Note`å¦‚æœä½ è¦æ£€æŸ¥`Docker`æ˜¯å¦ä½¿ç”¨`systemd cgroup`ç®¡ç†ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼ˆä¸‹é¢çš„è¾“å‡ºè¡¨ç¤ºå¯ç”¨äº†`systemd cgroup`é©±åŠ¨ç¨‹åºï¼‰
```shell
 $ docker info  
 ...  
 Cgroup Driver: systemd  
 Cgroup Version: 1
```
### ä½¿ç”¨`containerd`/`runc`çš„Kubernetesç¯å¢ƒ
#### ç‰¹å®šæ¡ä»¶
- åœ¨`containerd`é…ç½®æ–‡ä»¶ï¼ˆé€šå¸¸ä½äºï¼š`/etc/containerd/config.toml`ï¼‰ä¸­è®¾ç½®`SystemdCgroup = true`ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
  
```shell
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia.options]
BinaryName = "/usr/local/nvidia/toolkit/nvidia-container-runtime"
...
SystemdCgroup = true
```
> Note:å¦‚æœä½ æƒ³è¦æ£€æŸ¥`containerd`æ˜¯å¦ä½¿ç”¨`systemd cgroup`ç®¡ç†ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼ˆä¸‹é¢çš„è¾“å‡ºè¡¨ç¤ºå¯ç”¨äº†`systemd cgroup`é©±åŠ¨ç¨‹åºï¼‰
```shell
$ sudo crictl info  
...  
"runtimes": {
    "nvidia": {
        "runtimeType": "io.containerd.runc.v2",
        ...
        "options": {
          "BinaryName": "/usr/local/nvidia/toolkit/nvidia-container-runtime",
          ...
          "ShimCgroup": "",
          "SystemdCgroup": true
```
### ä½¿ç”¨`cri-o`/`runc`çš„Kubernetesç¯å¢ƒ
#### ç‰¹å®šæ¡ä»¶
åœ¨`cri-o`é…ç½®æ–‡ä»¶ä¸­å¯ç”¨äº†`systemd`çš„`cgroup_manager`ï¼ˆé€šå¸¸ä½äºï¼š`/etc/crio/crio.confæˆ–/etc/crio/crio.conf.d/00-default`ï¼‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆä½¿ç”¨`OpenShift`çš„ç¤ºä¾‹ï¼‰ï¼š
```shell
[crio.runtime]
...
cgroup_manager = "systemd"

hooks_dir = [
"/etc/containers/oci/hooks.d",
"/run/containers/oci/hooks.d",
"/usr/share/containers/oci/hooks.d",
]
```

Note: `Podman`ç¯å¢ƒé»˜è®¤ä½¿ç”¨`crun`ï¼Œå¹¶ä¸”é™¤éåˆ»æ„å°†`runc`é…ç½®ä¸ºè¦ä½¿ç”¨çš„åº•å±‚å®¹å™¨è¿è¡ŒCRIæ—¶ï¼Œå¦åˆ™ä¸ä¼šå—åˆ°è¿™ä¸ªé—®é¢˜çš„å½±å“ã€‚
## å¦‚ä½•æ£€æŸ¥ä½ çš„ç¯å¢ƒæ˜¯å¦å—åˆ°å½±å“

æ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤ç¡®è®¤æ‚¨çš„ç³»ç»Ÿæ˜¯å¦å—åˆ°å½±å“ã€‚æ‚¨å¯ä»¥è¿™äº›æ­¥éª¤æ¥ç¡®è®¤é”™è¯¯æ˜¯å¦å¯ä»¥å¤ç°ã€‚
### Dockerç¯å¢ƒ

è¿è¡Œä¸€ä¸ªæµ‹è¯•çš„`container`ï¼š
```shell
$ docker run -d --rm --runtime=nvidia --gpus all \
    --device=/dev/nvidia-uvm \
    --device=/dev/nvidia-uvm-tools \
    --device=/dev/nvidia-modeset \
    --device=/dev/nvidiactl \
    --device=/dev/nvidia0 \
    nvcr.io/nvidia/cuda:12.0.0-base-ubuntu20.04 bash -c "while [ true ]; do nvidia-smi -L; sleep 5; done"  

bc045274b44bdf6ec2e4cc10d2968d1d2a046c47cad0a1d2088dc0a430add24b
```
> Note è¯·ç¡®ä¿ä½ æµ‹è¯•çš„`container`æŒ‚è½½ä¸åŒçš„è®¾å¤‡ï¼ˆå¦‚ä¸Šæ‰€ç¤ºï¼‰ã€‚è¿™æ˜¯ç¡®å®šæ­¤ç‰¹å®šé—®é¢˜çš„å¿…è¦æ¡ä»¶ã€‚

å¦‚æœæ‚¨çš„ç³»ç»Ÿæœ‰è¶…è¿‡1ä¸ªGPUï¼Œè¯·åœ¨ä¸Šè¿°å‘½ä»¤åé™„åŠ é¢å¤–çš„ --device æŒ‚è½½ã€‚æ‹¥æœ‰2ä¸ªGPUçš„ç³»ç»Ÿçš„ä¾‹å­ï¼š
```shell
$ docker run -d --rm --runtime=nvidia --gpus all \
    ...
    --device=/dev/nvidia0 \
    --device=/dev/nvidia1 \
    ...
```
æ­¤æ—¶å¯ä»¥æŸ¥çœ‹`container`çš„log
```shell
$ docker logs bc045274b44bdf6ec2e4cc10d2968d1d2a046c47cad0a1d2088dc0a430add24b

GPU 0: Tesla K80 (UUID: GPU-05ea3312-64dd-a4e7-bc72-46d2f6050147)
GPU 0: Tesla K80 (UUID: GPU-05ea3312-64dd-a4e7-bc72-46d2f6050147)
```
ç„¶åä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤æ¥è§¦å‘ `daemon-reload`
```shell
$ sudo systemctl daemon-reload
```
æ­¤æ—¶å†æ¬¡æŸ¥çœ‹`container`çš„log, æˆ‘ä»¬å¯ä»¥å¤ç°è¿™ä¸ªé—®é¢˜
```shell
$ docker logs bc045274b44bdf6ec2e4cc10d2968d1d2a046c47cad0a1d2088dc0a430add24b

GPU 0: Tesla K80 (UUID: GPU-05ea3312-64dd-a4e7-bc72-46d2f6050147)
GPU 0: Tesla K80 (UUID: GPU-05ea3312-64dd-a4e7-bc72-46d2f6050147)
GPU 0: Tesla K80 (UUID: GPU-05ea3312-64dd-a4e7-bc72-46d2f6050147)
GPU 0: Tesla K80 (UUID: GPU-05ea3312-64dd-a4e7-bc72-46d2f6050147)
Failed to initialize NVML: Unknown Error
Failed to initialize NVML: Unknown Error
```
### K8s ç¯å¢ƒ
è¿è¡Œä¸€ä¸ªæµ‹è¯•çš„`Pod`ï¼š
```shell
$ cat nvidia-smi-loop.yaml

apiVersion: v1
kind: Pod
metadata:
  name: cuda-nvidia-smi-loop
spec:
  restartPolicy: OnFailure
  containers:
  - name: cuda
    image: "nvcr.io/nvidia/cuda:12.0.0-base-ubuntu20.04"
    command: ["/bin/sh", "-c"]
    args: ["while true; do nvidia-smi -L; sleep 5; done"]
    resources:
      limits:
        nvidia.com/gpu: 1


$ kubectl apply -f nvidia-smi-loop.yaml  
 
pod/cuda-nvidia-smi-loop created
```
æ­¤æ—¶å¯ä»¥æŸ¥çœ‹`Pod`çš„log
```shell
$ kubectl logs cuda-nvidia-smi-loop

GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-551720f0-caf0-22b7-f525-2a51a6ab478d)
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-551720f0-caf0-22b7-f525-2a51a6ab478d)
```
ç„¶åä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤æ¥è§¦å‘ `daemon-reload`
```shell
$ sudo systemctl daemon-reload
```
æ­¤æ—¶å†æ¬¡æŸ¥çœ‹`Pod`çš„log, æˆ‘ä»¬å¯ä»¥å¤ç°è¿™ä¸ªé—®é¢˜
```shell
$ kubectl logs cuda-nvidia-smi-loop

GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-551720f0-caf0-22b7-f525-2a51a6ab478d)
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-551720f0-caf0-22b7-f525-2a51a6ab478d)
Failed to initialize NVML: Unknown Error
Failed to initialize NVML: Unknown Error
```

## Workarounds

ä¸‹é¢çš„è§£å†³æ–¹æ³•é€‚ç”¨äºç‹¬ç«‹çš„dockerç¯å¢ƒå’Œk8sç¯å¢ƒï¼ˆæŒ‰ç…§æ¨èé¡ºåºğŸ‘æä¾›å¤šä¸ªé€‰é¡¹ï¼›æœ€æ¨èğŸ‘çš„é€‰é¡¹åœ¨æœ€ä¸Šé¢ï¼‰ï¼š
### Dockerç¯å¢ƒ

#### ä½¿ç”¨`nvidia-ctk`å·¥å…·:

NVIDIA Container Toolkit v1.12.0åŒ…å«äº†ä¸€ä¸ªåœ¨`/dev/char`ä¸­ä¸ºæ‰€æœ‰å¯èƒ½çš„NVIDIAè®¾å¤‡èŠ‚ç‚¹åˆ›å»ºç¬¦å·é“¾æ¥çš„å·¥å…·ï¼Œè¿™äº›èŠ‚ç‚¹å¯¹äºåœ¨å®¹å™¨ä¸­ä½¿ç”¨GPUæ˜¯å¿…è¦çš„ã€‚è¯¥å·¥å…·å¯ä»¥å¦‚ä¸‹è¿è¡Œï¼š

```shell
sudo nvidia-ctk system create-dev-char-symlinks \
    --create-all
```

è¿™ä¸ªå‘½ä»¤åº”è¯¥åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„å¯åŠ¨æ—¶è¿è¡Œï¼Œè¿™æ ·å®¹å™¨ä¸­ä½¿ç”¨GPUæ—¶å°±ä¸ä¼šå‡ºç°é—®é¢˜ã€‚åœ¨è¿è¡Œè¿™ä¸ªå‘½ä»¤ä¹‹å‰ï¼Œéœ€è¦ç¡®ä¿NVIDIAé©±åŠ¨çš„å†…æ ¸æ¨¡å—å·²ç»åŠ è½½ã€‚

ä¸€ä¸ªç®€å•çš„`udev`è§„åˆ™å¯ä»¥å¼ºåˆ¶æ‰§è¡Œè¿™ä¸€ç‚¹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```shell
# This will create /dev/char symlinks to all device nodes
ACTION=="add", DEVPATH=="/bus/pci/drivers/nvidia", RUN+="/usr/bin/nvidia-ctk system 	create-dev-char-symlinks --create-all"
```

å®‰è£…æ­¤è§„åˆ™çš„æ¨èçš„åœ°æ–¹æ˜¯ï¼š`/lib/udev/rules.d/71-nvidia-dev-char.rules`


åœ¨ä½¿ç”¨`NVIDIA GPU Driver Container`çš„æƒ…å†µä¸‹ï¼Œå¿…é¡»æŒ‡å®šé©±åŠ¨ç¨‹åºå®‰è£…çš„è·¯å¾„ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå‘½ä»¤åº”è¯¥ä¿®æ”¹ä¸ºï¼š

```shell
sudo nvidia-ctk system create-dev-symlinks \
        --create-all \
        --driver-root={{NVIDIA_DRIVER_ROOT}}
```

`{{NVIDIA_DRIVER_ROOT}}`æ˜¯NVIDIA GPU Driver containerå®‰è£…NVIDIA GPUé©±åŠ¨ç¨‹åºå¹¶åˆ›å»ºNVIDIAè®¾å¤‡èŠ‚ç‚¹çš„è·¯å¾„ã€‚

#### éšå¼åœ°ç¦ç”¨Dockerä¸­çš„`systemd cgroup`ç®¡ç†

è®¾ç½®`/etc/docker/daemon.json`æ–‡ä»¶ä¸­çš„å‚æ•°`"exec-opts": ["native.cgroupdriver=cgroupfs"]`å¹¶é‡å¯dockerã€‚


#### é™çº§docker.io

é™çº§åˆ°`docker.io`åŒ…ï¼Œå…¶ä¸­`systemd`ä¸æ˜¯é»˜è®¤çš„`cgroup`ç®¡ç†å™¨ï¼ˆå½“ç„¶ä¸è¦è¦†ç›–ï¼‰ã€‚

### K8s ç¯å¢ƒ

#### GPU Operator

ä½ å¯ä»¥ä½¿ç”¨`GPU Operator`çš„`22.9.2`ä»¥åŠä»¥ä¸Šç‰ˆæœ¬ï¼Œå®ƒä¼šè‡ªåŠ¨ä¿®å¤é›†ç¾¤ä¸­æ‰€æœ‰K8sèŠ‚ç‚¹ä¸Šçš„é—®é¢˜ï¼ˆæ­¤ä¿®å¤å·²ç»é›†æˆåˆ°[gpu-operator-validator](https://github.com/NVIDIA/gpu-operator/tree/master/validator)ä¸­ï¼Œå½“æ–°Nodeéƒ¨ç½²æˆ–æ¯æ¬¡Nodeé‡å¯æ—¶éƒ½ä¼šè¿è¡Œï¼‰ã€‚

#### k8s-device-plugin

å¯¹äºç›´æ¥ä½¿ç”¨k8s-device-pluginçš„åœºæ™¯æ¥è¯´ï¼ˆå³ä¸é€šè¿‡`GPU Operator`ä½¿ç”¨ï¼‰ï¼Œä½ å¯ä»¥å®‰è£…å¦‚ä¸Šä¸€èŠ‚æ‰€è¿°çš„`udev`è§„åˆ™æ¥è§£å†³æ­¤é—®é¢˜ã€‚ã€‚å¦‚æœä½ ä½¿ç”¨äº†containeræ¥å®‰è£…driverçš„è¯ï¼Œè¯·è¯·ç¡®ä¿ä¼ é€’æ­£ç¡®çš„`{{NVIDIA_DRIVER_ROOT}}`ã€‚è¯¦æƒ…è¯·å‚è€ƒ[configuration-option-details in k8s-device-plugin](https://github.com/NVIDIA/k8s-device-plugin?tab=readme-ov-file#configuration-option-details)

#### åœ¨`containerd`æˆ–`cri-o`éšå¼åœ°ç¦ç”¨`systemd cgroup`

ä»cri-oé…ç½®æ–‡ä»¶ä¸­åˆ é™¤å‚æ•°`cgroup_manager = "systemd"`ï¼ˆé€šå¸¸ä½äºï¼š`/etc/crio/crio.conf`æˆ–`/etc/crio/crio.conf.d/00-default`ï¼‰ï¼Œç„¶åé‡å¯cri-oã€‚

#### é™çº§`containerd`

é™çº§åˆ°`containerd.io`åŒ…çš„ä¸€ä¸ªç‰ˆæœ¬ï¼Œå…¶ä¸­`systemd`ä¸æ˜¯é»˜è®¤çš„`cgroup`ç®¡ç†å™¨ï¼ˆå½“ç„¶ä¸è¦è¦†ç›–ï¼‰ã€‚

## ç›¸å…³é—®é¢˜é“¾æ¥ğŸ”—
- ["Failed to initialize NVML: Unknown Error" after random amount of time](https://github.com/NVIDIA/nvidia-docker/issues/1671)
- [NOTICE: Containers losing access to GPUs with error: "Failed to initialize NVML: Unknown Error" ](https://github.com/NVIDIA/nvidia-docker/issues/1730)
- [Updating cpu-manager-policy=static causes NVML unknown error](https://github.com/NVIDIA/nvidia-docker/issues/966#issuecomment-610928514)